# Main entrypoint of the workflow.
# Please follow the best practices:
# https://snakemake.readthedocs.io/en/stable/snakefiles/best_practices.html,
# in particular regarding the standardized folder structure mentioned there.
import os
import pandas as pd
import itertools


configfile: "config/config.yaml"


samples = (
    pd.read_csv(
        config["samples"],
        sep="\t",
        dtype={"sample": str, "fq1": str, "fq2": str},
        comment="#",
    )
    .set_index("sample", drop=False)
    .sort_index()
)

# def get_input_fastqs(wildcards):
#    return config["samples"][wildcards.sample]

SAMPLE = samples["sample"].tolist()


wildcard_constraints:
    sample="|".join(samples["sample"]),


rule all:
    input:
        "results/ska.distances.tsv",


rule map_reads:
    input:
        ref=config["genome"],
        read1=samples["fq1"],
        read2=samples["fq2"],
    output:
        temp("results/mapped_reads/{sample}.sam"),
    threads: config["threads"]
    log:
        "logs/bowtie/{sample}.log",
    conda:
        "envs/bowtie.yaml"
    shell:
        "(bowtie2 --sensitive -p {threads} -x {input.ref} -1 {input.read1} -2 {input.read2} -S {output}) > {log}"


rule samtools_sort:
    input:
        "results/mapped_reads/{sample}.sam",
    output:
        protected("results/sorted_bam/{sample}.sorted.bam"),
    threads: config["threads"]
    log:
        "logs/samtools_sort/{sample}.log",
    conda:
        "envs/samtools.yaml"
    shell:
        "(samtools view -bS {input} |"
        "samtools view -b -F12 - |"
        "samtools sort -n - -o {output} -@ {threads}) > {log}"


rule output_fastq:
    input:
        "results/sorted_bam/{sample}.sorted.bam",
    output:
        read1="results/mapped_reads/{sample}.mapped.R1.fastq",
        read2="results/mapped_reads/{sample}.mapped.R2.fastq",
    threads: config["threads"]
    log:
        "logs/output_fastq/{sample}.log",
    conda:
        "envs/samtools.yaml"
    shell:
        "(samtools fastq  -1 {output.read1} -2 {output.read2} -@ {threads};"
        "pigz -9 {output.read1};"
        "pigz -9 {output.read2}) > {log}"


rule ska_fastq:
    input:
        read1="results/mapped_reads/{sample}.mapped.R1.fastq",
        read2="results/mapped_reads/{sample}.mapped.R2.fastq",
    output:
        "results/skf_files/{sample}.skf",
    params:
        name="{sample}",
    threads: 1
    log:
        "logs/ska_fastq/{sample}.log",
    conda:
        "envs/ska.yaml"
    shell:
        "(ska fastq -o results/skf_files/{params.name} {input.read1} {input.read2}) > {log}"


rule ska_distance:
    input:
        file1="results/skf_files/{sample1}.skf",
        file2="results/skf_files/{sample2}.skf",
    output:
        "results/distances/{sample1}_{sample2}.distances.tsv",
    params:
        name="{sample1}_{sample2}",
    threads: 1
    log:
        "logs/ska_distance/{sample1}_{sample2}.log",
    conda:
        "envs/ska.yaml"
    shell:
        "(ska distance -c -o results/distances/{params.name} {input.file1} {input.file2}) > (log)"


combs = []
for x in itertools.combinations(SAMPLE, 2):
    combs.append("results/distances/%s_%s.distances.tsv" % (x[0], x[1]))


rule cat_distance_files:
    input:
        combs,
    output:
        "results/ska.distances.tsv",
    log:
        "logs/ska_distance/cat_distance_files.log",
    shell:
        #"cat {input} > {output}" #better cat, print header and remove from all files
        "(awk 'NR < 2 {{print $0 ; next}} !/^Sample 1/{{print $0}}' {input} > {output}) > {log}"
